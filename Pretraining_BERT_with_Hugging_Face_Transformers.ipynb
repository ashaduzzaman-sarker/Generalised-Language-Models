{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMPr37QHAroBn3OQ0qS+09x",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "9ee4209c8eeb4ef7a68bf3b0feeb3759": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bb46246a20d04116a3758f310b468771",
              "IPY_MODEL_a340eb2010ec431b9eb67dfd3ef6647e",
              "IPY_MODEL_e62ad42362a542b88a6a93630aa85723"
            ],
            "layout": "IPY_MODEL_5a4bf866803e427eaa4d0073421f933c"
          }
        },
        "bb46246a20d04116a3758f310b468771": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_95f8319dd14d43a19cb733377e8ceb20",
            "placeholder": "​",
            "style": "IPY_MODEL_16243b534fab45fcab5965a754a70c63",
            "value": "Map: 100%"
          }
        },
        "a340eb2010ec431b9eb67dfd3ef6647e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_20b93886cef747e9b4d9238ad161ddab",
            "max": 4358,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4774793c437944d5ad8bf89f6b16ce67",
            "value": 4358
          }
        },
        "e62ad42362a542b88a6a93630aa85723": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cdc1bf3e1d8e479d8cbc6e0a2cca6780",
            "placeholder": "​",
            "style": "IPY_MODEL_ddb668c8a891428a89f3b448344c9247",
            "value": " 4358/4358 [00:08&lt;00:00, 562.30 examples/s]"
          }
        },
        "5a4bf866803e427eaa4d0073421f933c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "95f8319dd14d43a19cb733377e8ceb20": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "16243b534fab45fcab5965a754a70c63": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "20b93886cef747e9b4d9238ad161ddab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4774793c437944d5ad8bf89f6b16ce67": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cdc1bf3e1d8e479d8cbc6e0a2cca6780": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ddb668c8a891428a89f3b448344c9247": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2c66aac41d7849138ae89e84490772c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_36227aea009f4a4d9993bf65028b1b2a",
              "IPY_MODEL_18f000e5f11f482db0b5c72ffb0650ac",
              "IPY_MODEL_4e49a659033d42c6a5e47b1c605fd2db"
            ],
            "layout": "IPY_MODEL_420ec2e85d3547ec8268982d91834221"
          }
        },
        "36227aea009f4a4d9993bf65028b1b2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_282ccb418b044fc1a80c46caf8e2b04f",
            "placeholder": "​",
            "style": "IPY_MODEL_09c1ca2c430e433580fb8aea8477998e",
            "value": "Map: 100%"
          }
        },
        "18f000e5f11f482db0b5c72ffb0650ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6b6cff7a59db46c09eb0e3079c306c48",
            "max": 1000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3a7a9ab5213747b9b19818e53e428a2f",
            "value": 1000
          }
        },
        "4e49a659033d42c6a5e47b1c605fd2db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3426eecad0a14b2bbadfcc264ecd2fc2",
            "placeholder": "​",
            "style": "IPY_MODEL_7353b8c6203c42218454f32817949f0e",
            "value": " 1000/1000 [00:00&lt;00:00, 1343.39 examples/s]"
          }
        },
        "420ec2e85d3547ec8268982d91834221": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "282ccb418b044fc1a80c46caf8e2b04f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "09c1ca2c430e433580fb8aea8477998e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6b6cff7a59db46c09eb0e3079c306c48": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3a7a9ab5213747b9b19818e53e428a2f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3426eecad0a14b2bbadfcc264ecd2fc2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7353b8c6203c42218454f32817949f0e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b072f8a414354ddf86538f7bd9166dba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_07385f8266284dac99b345a43c69c055",
              "IPY_MODEL_bd5b61ec269a4446864dfccd72439388",
              "IPY_MODEL_4c012df2e3f8462b85f3ad8a956a4365"
            ],
            "layout": "IPY_MODEL_4b88bf14ae1741d0a5bd5eeb97e75c5c"
          }
        },
        "07385f8266284dac99b345a43c69c055": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6913fee9f6044dc5903d086ee9c034c0",
            "placeholder": "​",
            "style": "IPY_MODEL_1bd2d5dd8a834c9691bb578262615592",
            "value": "Map: 100%"
          }
        },
        "bd5b61ec269a4446864dfccd72439388": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1ada7767a75249b09f7bf0236ad084d4",
            "max": 1000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1643e3041fac4744b8d92e317e148e69",
            "value": 1000
          }
        },
        "4c012df2e3f8462b85f3ad8a956a4365": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_77c48056bb1c413ea2661b34ba039447",
            "placeholder": "​",
            "style": "IPY_MODEL_a2bfbd79df944edbbeb381b88ce16b97",
            "value": " 1000/1000 [00:00&lt;00:00, 1427.56 examples/s]"
          }
        },
        "4b88bf14ae1741d0a5bd5eeb97e75c5c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6913fee9f6044dc5903d086ee9c034c0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1bd2d5dd8a834c9691bb578262615592": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1ada7767a75249b09f7bf0236ad084d4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1643e3041fac4744b8d92e317e148e69": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "77c48056bb1c413ea2661b34ba039447": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a2bfbd79df944edbbeb381b88ce16b97": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ashaduzzaman-sarker/Transfer-learning-and-Generalised-Language-Models/blob/main/Pretraining_BERT_with_Hugging_Face_Transformers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pretraining BERT using Hugging Face Transformers on NSP and MLM\n",
        "\n",
        "## Introduction:\n",
        "\n",
        "- **BERT Overview:**\n",
        "  - **BERT (Bidirectional Encoder Representations from Transformers):** A model that leverages the Transformer architecture for natural language processing (NLP) tasks.\n",
        "\n",
        "![](https://miro.medium.com/v2/resize:fit:1400/1*B-Kd1JHDms479Id2uCW22A.png)\n",
        "\n",
        "  - **Transfer Learning:** Similar to techniques used in computer vision, BERT can be pretrained on large datasets and then fine-tuned for specific NLP tasks.\n",
        "\n",
        "- **Transformer Architecture:**\n",
        "  - **Attention Mechanism:** The core of Transformer, which learns contextual relations between words or subwords in a text.\n",
        "  - **Encoder-Decoder Structure:** In its original form, Transformer includes both an encoder (reads text input) and a decoder (produces predictions). BERT uses only the encoder to generate a language model.\n",
        "  - **Bidirectionality:** Unlike directional models that process text sequentially, the Transformer encoder in BERT reads the entire sequence simultaneously, allowing it to capture context from both directions.\n",
        "\n",
        "![](https://storrs.io/content/images/2021/06/Screen-Shot-2021-06-27-at-8.36.36-AM.png)\n",
        "\n",
        "- **Training Objectives for BERT:**\n",
        "  - **Masked Language Modeling (MLM):** 15% of the words in a sequence are masked, and the model predicts the original words using the context from the surrounding words.\n",
        "  - **Next Sentence Prediction (NSP):** The model predicts whether the second sentence in a pair is the subsequent sentence in the original document or a random sentence from the corpus.\n",
        "\n",
        "- **Training and Pretraining:**\n",
        "  - **Google's Pretrained BERT:** While a pretrained BERT model for English is available, there may be a need to pretrain BERT from scratch for other languages or domains.\n",
        "  - **Pretraining Process:** The example provided uses the WikiText English dataset and trains BERT from scratch, optimizing both MLM and NSP objectives with the 🤗 Transformers library."
      ],
      "metadata": {
        "id": "HHDWPp_DWveC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup"
      ],
      "metadata": {
        "id": "B8Fr-XL-Yb3D"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VTG-lJPdw1f-"
      },
      "outputs": [],
      "source": [
        "!pip install git+https://github.com/huggingface/transformers.git\n",
        "!pip install datasets\n",
        "!pip install huggingface-hub\n",
        "!pip install nltk\n",
        "\n",
        "!pip install -q upgrade tensorflow keras"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports"
      ],
      "metadata": {
        "id": "CMWrH0p2YuH6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "import random\n",
        "import logging\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "nltk.download(\"punkt\")\n",
        "\n",
        "tf.keras.utils.set_random_seed(42)\n",
        "\n",
        "# Only log error message\n",
        "tf.get_logger().setLevel(logging.ERROR)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nD--JrdmYtNB",
        "outputId": "ee5e7cb1-a180-4272-96f3-eeaf35529933"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define Variables"
      ],
      "metadata": {
        "id": "UrKyDKNmZUFe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "TOKENIZER_BATCH_SIZE = 128    # Batch size of tokenizer to train\n",
        "TOKENIZER_VOCABULARY = 25000    # Total number of unique subwords the tokenizer can have\n",
        "\n",
        "BLOCK_SIZE = 128    # The maximum sequence length in an input\n",
        "NSP_PROB = 0.50    # Probability of next sentence prediction\n",
        "SHORT_SEQ_PROB = 0.1    # Probability of creating short sequences\n",
        "MAX_LENGTH = 512    # Maximum sequence length\n",
        "\n",
        "MLM_PROB = 0.20    # Probability of masking a token for MLM\n",
        "\n",
        "TRAIN_BATCH_SIZE = 2    # Batch size for training\n",
        "MAX_EPOCHS = 1    # Maximum number of epochs\n",
        "LEARNING_RATE = 1e-5    # Learning rate for training\n",
        "\n",
        "MODEL_CHECKPOINT = \"bert-base-uncased\"    # Model checkpoint to use"
      ],
      "metadata": {
        "id": "gTQsyAlvZTaY"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load the WikiText dataset\n",
        "\n",
        "- **WikiText Dataset:**\n",
        "  - A language modeling dataset containing over 100 million tokens extracted from \"Good\" and \"Featured\" articles on Wikipedia.\n",
        "  \n",
        "- **Loading the Dataset:**\n",
        "  - The dataset is available via the 🤗 Datasets library.\n",
        "  - For demonstration purposes, only the train split of the dataset is used.\n",
        "  \n",
        "- **Using the `load_dataset` Function:**\n",
        "  - The `load_dataset` function from 🤗 Datasets is utilized to download and load the WikiText dataset.\n",
        "  \n",
        "- **Focus:**\n",
        "  - The example emphasizes working with the train split, simplifying the demonstration."
      ],
      "metadata": {
        "id": "hYywBpJKavIN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "dataset = load_dataset(\"wikitext\", \"wikitext-2-raw-v1\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "48xxFWiRamJv",
        "outputId": "02a0d4d8-bbd0-476e-e301-1cfa7a7b49c3"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "615UDHIAa_yB",
        "outputId": "cc17df16-7a6f-4856-f872-8433275f45af"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DatasetDict({\n",
            "    test: Dataset({\n",
            "        features: ['text'],\n",
            "        num_rows: 4358\n",
            "    })\n",
            "    train: Dataset({\n",
            "        features: ['text'],\n",
            "        num_rows: 36718\n",
            "    })\n",
            "    validation: Dataset({\n",
            "        features: ['text'],\n",
            "        num_rows: 3760\n",
            "    })\n",
            "})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training a new Tokenizer\n",
        "\n",
        "- **Training a Tokenizer:**\n",
        "  - Custom tokenizer captures the specific vocabulary and subwords in your dataset.\n",
        "  - Essential for Transformer models using subword tokenization.\n",
        "\n",
        "- **🤗 Transformers Tokenizer:**\n",
        "  - Converts inputs into token IDs and prepares data for the model.\n",
        "\n",
        "- **Process:**\n",
        "  - Start by listing all raw documents from the WikiText corpus to train the tokenizer."
      ],
      "metadata": {
        "id": "VSMTuJfubsz_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "all_texts = [\n",
        "    doc for doc in dataset[\"train\"][\"text\"] if len(doc) > 0 and not doc.startswith(\" =\")\n",
        "]"
      ],
      "metadata": {
        "id": "ikgTPtrHbYOy"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a batch iterator for tokenizer training\n",
        "def batch_iterator():\n",
        "    for i in range(0, len(all_texts), TOKENIZER_BATCH_SIZE):\n",
        "        yield all_texts[i : i + TOKENIZER_BATCH_SIZE]"
      ],
      "metadata": {
        "id": "1B26K6KMcPpM"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "In this notebook, we replicate an existing tokenizer by training a new version\n",
        "with the same algorithms and parameters, starting by loading the desired\n",
        "tokenizer model (e.g., BERT-CASED).\n",
        "\"\"\"\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_CHECKPOINT)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q0BG43SXcrUH",
        "outputId": "91aecf66-f9f2-4aa0-bfd9-c1a6a3d45be0"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Next, we train our tokenizer using the full train split of the Wikitext-2 dataset.\n",
        "tokenizer = tokenizer.train_new_from_iterator(\n",
        "    batch_iterator(), vocab_size=TOKENIZER_VOCABULARY\n",
        ")"
      ],
      "metadata": {
        "id": "mDlAjl3sc9Qq"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Pre-processing\n"
      ],
      "metadata": {
        "id": "-qGbBpP9dTsl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[\"train\"] = dataset[\"train\"].select([i for i in range(1000)])\n",
        "dataset[\"validation\"] = dataset[\"validation\"].select([i for i in range(1000)])"
      ],
      "metadata": {
        "id": "VUR2oZr8dKWi"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **Preprocessing for BERT Pretraining:**\n",
        "  - **Tasks:** Prepare data for the Next Sentence Prediction (NSP) and Masked Language Modeling (MLM) tasks.\n",
        "  - **DataCollator:** 🤗 Transformers provides a `DataCollatorForLanguageModeling` for MLM, but NSP requires manual preparation.\n",
        "\n",
        "- **`prepare_train_features` Function:**\n",
        "  - **NSP Preparation:** Create sentence pairs (A, B) where B either follows A or is randomly sampled, and assign labels (1 if B follows A, 0 if not).\n",
        "  - **Tokenization:** Convert text to token IDs for BERT's embedding lookup.\n",
        "  - **Additional Inputs:** Generate necessary inputs like `token_type_ids` and `attention_mask` for the model."
      ],
      "metadata": {
        "id": "4pmcg6tydrIV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We define the maximum number of tokens after tokenization that each training sample\n",
        "# will have\n",
        "max_num_tokens = BLOCK_SIZE - tokenizer.num_special_tokens_to_add(pair=True)\n",
        "\n",
        "\n",
        "def prepare_train_features(examples):\n",
        "\n",
        "    \"\"\"Function to prepare features for NSP task\n",
        "\n",
        "    Arguments:\n",
        "      examples: A dictionary with 1 key (\"text\")\n",
        "        text: List of raw documents (str)\n",
        "    Returns:\n",
        "      examples:  A dictionary with 4 keys\n",
        "        input_ids: List of tokenized, concatnated, and batched\n",
        "          sentences from the individual raw documents (int)\n",
        "        token_type_ids: List of integers (0 or 1) corresponding\n",
        "          to: 0 for senetence no. 1 and padding, 1 for sentence\n",
        "          no. 2\n",
        "        attention_mask: List of integers (0 or 1) corresponding\n",
        "          to: 1 for non-padded tokens, 0 for padded\n",
        "        next_sentence_label: List of integers (0 or 1) corresponding\n",
        "          to: 1 if the second sentence actually follows the first,\n",
        "          0 if the senetence is sampled from somewhere else in the corpus\n",
        "    \"\"\"\n",
        "\n",
        "    # Remove un-wanted samples from the training set\n",
        "    examples[\"document\"] = [\n",
        "        d.strip() for d in examples[\"text\"] if len(d) > 0 and not d.startswith(\" =\")\n",
        "    ]\n",
        "    # Split the documents from the dataset into it's individual sentences\n",
        "    examples[\"sentences\"] = [\n",
        "        nltk.tokenize.sent_tokenize(document) for document in examples[\"document\"]\n",
        "    ]\n",
        "    # Convert the tokens into ids using the trained tokenizer\n",
        "    examples[\"tokenized_sentences\"] = [\n",
        "        [tokenizer.convert_tokens_to_ids(tokenizer.tokenize(sent)) for sent in doc]\n",
        "        for doc in examples[\"sentences\"]\n",
        "    ]\n",
        "\n",
        "    # Define the outputs\n",
        "    examples[\"input_ids\"] = []\n",
        "    examples[\"token_type_ids\"] = []\n",
        "    examples[\"attention_mask\"] = []\n",
        "    examples[\"next_sentence_label\"] = []\n",
        "\n",
        "    for doc_index, document in enumerate(examples[\"tokenized_sentences\"]):\n",
        "\n",
        "        current_chunk = []  # a buffer stored current working segments\n",
        "        current_length = 0\n",
        "        i = 0\n",
        "\n",
        "        # We *usually* want to fill up the entire sequence since we are padding\n",
        "        # to `block_size` anyways, so short sequences are generally wasted\n",
        "        # computation. However, we *sometimes*\n",
        "        # (i.e., short_seq_prob == 0.1 == 10% of the time) want to use shorter\n",
        "        # sequences to minimize the mismatch between pretraining and fine-tuning.\n",
        "        # The `target_seq_length` is just a rough target however, whereas\n",
        "        # `block_size` is a hard limit.\n",
        "        target_seq_length = max_num_tokens\n",
        "\n",
        "        if random.random() < SHORT_SEQ_PROB:\n",
        "            target_seq_length = random.randint(2, max_num_tokens)\n",
        "\n",
        "        while i < len(document):\n",
        "            segment = document[i]\n",
        "            current_chunk.append(segment)\n",
        "            current_length += len(segment)\n",
        "            if i == len(document) - 1 or current_length >= target_seq_length:\n",
        "                if current_chunk:\n",
        "                    # `a_end` is how many segments from `current_chunk` go into the `A`\n",
        "                    # (first) sentence.\n",
        "                    a_end = 1\n",
        "                    if len(current_chunk) >= 2:\n",
        "                        a_end = random.randint(1, len(current_chunk) - 1)\n",
        "\n",
        "                    tokens_a = []\n",
        "                    for j in range(a_end):\n",
        "                        tokens_a.extend(current_chunk[j])\n",
        "\n",
        "                    tokens_b = []\n",
        "\n",
        "                    if len(current_chunk) == 1 or random.random() < NSP_PROB:\n",
        "                        is_random_next = True\n",
        "                        target_b_length = target_seq_length - len(tokens_a)\n",
        "\n",
        "                        # This should rarely go for more than one iteration for large\n",
        "                        # corpora. However, just to be careful, we try to make sure that\n",
        "                        # the random document is not the same as the document\n",
        "                        # we're processing.\n",
        "                        for _ in range(10):\n",
        "                            random_document_index = random.randint(\n",
        "                                0, len(examples[\"tokenized_sentences\"]) - 1\n",
        "                            )\n",
        "                            if random_document_index != doc_index:\n",
        "                                break\n",
        "\n",
        "                        random_document = examples[\"tokenized_sentences\"][\n",
        "                            random_document_index\n",
        "                        ]\n",
        "                        random_start = random.randint(0, len(random_document) - 1)\n",
        "                        for j in range(random_start, len(random_document)):\n",
        "                            tokens_b.extend(random_document[j])\n",
        "                            if len(tokens_b) >= target_b_length:\n",
        "                                break\n",
        "                        # We didn't actually use these segments so we \"put them back\" so\n",
        "                        # they don't go to waste.\n",
        "                        num_unused_segments = len(current_chunk) - a_end\n",
        "                        i -= num_unused_segments\n",
        "                    else:\n",
        "                        is_random_next = False\n",
        "                        for j in range(a_end, len(current_chunk)):\n",
        "                            tokens_b.extend(current_chunk[j])\n",
        "\n",
        "                    input_ids = tokenizer.build_inputs_with_special_tokens(\n",
        "                        tokens_a, tokens_b\n",
        "                    )\n",
        "                    # add token type ids, 0 for sentence a, 1 for sentence b\n",
        "                    token_type_ids = tokenizer.create_token_type_ids_from_sequences(\n",
        "                        tokens_a, tokens_b\n",
        "                    )\n",
        "\n",
        "                    padded = tokenizer.pad(\n",
        "                        {\"input_ids\": input_ids, \"token_type_ids\": token_type_ids},\n",
        "                        padding=\"max_length\",\n",
        "                        max_length=MAX_LENGTH,\n",
        "                    )\n",
        "\n",
        "                    examples[\"input_ids\"].append(padded[\"input_ids\"])\n",
        "                    examples[\"token_type_ids\"].append(padded[\"token_type_ids\"])\n",
        "                    examples[\"attention_mask\"].append(padded[\"attention_mask\"])\n",
        "                    examples[\"next_sentence_label\"].append(1 if is_random_next else 0)\n",
        "                    current_chunk = []\n",
        "                    current_length = 0\n",
        "            i += 1\n",
        "\n",
        "    # We delete all the un-necessary columns from our dataset\n",
        "    del examples[\"document\"]\n",
        "    del examples[\"sentences\"]\n",
        "    del examples[\"text\"]\n",
        "    del examples[\"tokenized_sentences\"]\n",
        "\n",
        "    return examples\n",
        "\n",
        "\n",
        "tokenized_dataset = dataset.map(\n",
        "    prepare_train_features, batched=True, remove_columns=[\"text\"], num_proc=1,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151,
          "referenced_widgets": [
            "9ee4209c8eeb4ef7a68bf3b0feeb3759",
            "bb46246a20d04116a3758f310b468771",
            "a340eb2010ec431b9eb67dfd3ef6647e",
            "e62ad42362a542b88a6a93630aa85723",
            "5a4bf866803e427eaa4d0073421f933c",
            "95f8319dd14d43a19cb733377e8ceb20",
            "16243b534fab45fcab5965a754a70c63",
            "20b93886cef747e9b4d9238ad161ddab",
            "4774793c437944d5ad8bf89f6b16ce67",
            "cdc1bf3e1d8e479d8cbc6e0a2cca6780",
            "ddb668c8a891428a89f3b448344c9247",
            "2c66aac41d7849138ae89e84490772c9",
            "36227aea009f4a4d9993bf65028b1b2a",
            "18f000e5f11f482db0b5c72ffb0650ac",
            "4e49a659033d42c6a5e47b1c605fd2db",
            "420ec2e85d3547ec8268982d91834221",
            "282ccb418b044fc1a80c46caf8e2b04f",
            "09c1ca2c430e433580fb8aea8477998e",
            "6b6cff7a59db46c09eb0e3079c306c48",
            "3a7a9ab5213747b9b19818e53e428a2f",
            "3426eecad0a14b2bbadfcc264ecd2fc2",
            "7353b8c6203c42218454f32817949f0e",
            "b072f8a414354ddf86538f7bd9166dba",
            "07385f8266284dac99b345a43c69c055",
            "bd5b61ec269a4446864dfccd72439388",
            "4c012df2e3f8462b85f3ad8a956a4365",
            "4b88bf14ae1741d0a5bd5eeb97e75c5c",
            "6913fee9f6044dc5903d086ee9c034c0",
            "1bd2d5dd8a834c9691bb578262615592",
            "1ada7767a75249b09f7bf0236ad084d4",
            "1643e3041fac4744b8d92e317e148e69",
            "77c48056bb1c413ea2661b34ba039447",
            "a2bfbd79df944edbbeb381b88ce16b97"
          ]
        },
        "id": "XdDm_gDsdw2_",
        "outputId": "8870c12d-0cd4-4489-91e4-6797ca4a14f9"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/4358 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9ee4209c8eeb4ef7a68bf3b0feeb3759"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2c66aac41d7849138ae89e84490772c9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b072f8a414354ddf86538f7bd9166dba"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **Masked Language Modeling (MLM) Preprocessing:**\n",
        "  - **Token Masking:** Randomly replace some tokens with `[MASK]` and adjust labels to include only the masked tokens.\n",
        "  - **Special Tokens:** Ensure the `[MASK]` token is included if you trained your own tokenizer.\n",
        "\n",
        "- **Using DataCollator:**\n",
        "  - **DataCollatorForLanguageModeling:** Utilize this collator from the 🤗 Transformers library to prepare the dataset for MLM.\n",
        "  - **Compatibility:** Works on the dataset already prepared for NSP.\n",
        "  - **Parameters:** Default parameters from the original BERT paper are used, with `return_tensors='tf'` to get `tf.Tensor` objects."
      ],
      "metadata": {
        "id": "R2cfjVtonIyh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import DataCollatorForLanguageModeling\n",
        "\n",
        "collater = DataCollatorForLanguageModeling(\n",
        "    tokenizer=tokenizer, mlm=True, mlm_probability=MLM_PROB, return_tensors=\"tf\"\n",
        ")"
      ],
      "metadata": {
        "id": "GtN9mFnEka7T"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **Training Set Definition:**\n",
        "  - **`to_tf_dataset` Method:** Provided by 🤗 Datasets to integrate the dataset with the collator for model training.\n",
        "\n",
        "- **Key Parameters:**\n",
        "  - **`columns`:** Specifies the columns for independent variables.\n",
        "  - **`label_cols`:** Specifies the columns for dependent variables (labels).\n",
        "  - **`batch_size`:** Defines the batch size for training.\n",
        "  - **`shuffle`:** Option to shuffle the training dataset.\n",
        "  - **`collate_fn`:** Refers to the collator function used for data preparation."
      ],
      "metadata": {
        "id": "ZBk1NxB1neHy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train = tokenized_dataset[\"train\"].to_tf_dataset(\n",
        "    columns=[\"input_ids\", \"token_type_ids\", \"attention_mask\"],\n",
        "    label_cols=[\"labels\", \"next_sentence_label\"],\n",
        "    batch_size=TRAIN_BATCH_SIZE,\n",
        "    shuffle=True,\n",
        "    collate_fn=collater,\n",
        ")\n",
        "\n",
        "validation = tokenized_dataset[\"validation\"].to_tf_dataset(\n",
        "    columns=[\"input_ids\", \"token_type_ids\", \"attention_mask\"],\n",
        "    label_cols=[\"labels\", \"next_sentence_label\"],\n",
        "    batch_size=TRAIN_BATCH_SIZE,\n",
        "    shuffle=True,\n",
        "    collate_fn=collater,\n",
        ")"
      ],
      "metadata": {
        "id": "RINSRr_jnXEn"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Defining the model\n",
        "\n",
        "- **Model Configuration:**\n",
        "  - **Purpose:** Define model architecture parameters such as transformer layers, attention heads, and hidden dimensions.\n",
        "\n",
        "- **BertConfig Class:**\n",
        "  - **Usage:** Utilize `BertConfig` from the 🤗 Transformers library to set up the configuration.\n",
        "  - **Pretrained Model:** Use the `from_pretrained()` method with the model name (e.g., `bert-base-cased`) to replicate the configuration from the original BERT paper.\n"
      ],
      "metadata": {
        "id": "EtH--eSaoJry"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertConfig\n",
        "\n",
        "config = BertConfig.from_pretrained(MODEL_CHECKPOINT)"
      ],
      "metadata": {
        "id": "PO5RIlE_n66t"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **Model Definition:**\n",
        "  - **Class Used:** `TFBertForPreTraining` from the 🤗 Transformers library.\n",
        "  \n",
        "- **Functionality:**\n",
        "  - This class manages the entire process, including model definition, input handling, and loss calculation.\n",
        "  \n",
        "- **Ease of Use:**\n",
        "  - Simply define the model with the desired configuration, and the class takes care of the rest."
      ],
      "metadata": {
        "id": "K0BqG5Toocwd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TFBertForPreTraining\n",
        "\n",
        "model = TFBertForPreTraining(config)"
      ],
      "metadata": {
        "id": "06R5xwv8oX5h"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam')"
      ],
      "metadata": {
        "id": "Rhu9FnozohFt"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(train, validation_data=validation, epochs=MAX_EPOCHS)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GmhGQMOjonAw",
        "outputId": "3499ba6c-a7fa-4e3a-e919-c5e3194d3309"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "463/463 [==============================] - ETA: 0s - loss: 8.4419 "
          ]
        }
      ]
    }
  ]
}